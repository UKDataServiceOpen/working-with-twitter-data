{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.twitter.com/en/docs/twitter-api/premium/rules-and-filtering/operators-by-product\n",
    "\n",
    "we can use place, place_country and some similar. There doesn't seem to be any way of filtering retweets or replies without being on a paid tier.\n",
    "This can be a city, or a country. We can also restrict the language down to restrict english inputs if we need that.\n",
    "We can set a start and end date.\n",
    "Full_text is stored differently for retweets and tweets so we could take all, or choose only original content. we would hit the same API limit though.\n",
    "\n",
    "Limit seems to be at 300 per 15 minutes.\n",
    "We can run this every 15 minutes with different locations, and different time periods. I would ask here does time periods give us much?\n",
    "\n",
    "Twarc\n",
    "\n",
    "twarc2 configure\n",
    "YYYY-MM-DD\n",
    "-is_retweet -RT\n",
    "https://twittercommunity.com/t/exclude-retweets-in-api-v2/156357/5\n",
    "\n",
    "# get all tweets, january London\n",
    "twarc2 search --archive --max-results 100 --start-time \"2019-01-01\" --end-time \"2019-01-30\" \"(vegan OR plant-based OR plant based OR veganism) -is:retweet --geocode 51.507351,-0.127758,10mi\" data1.jsonl\n",
    "twarc2 csv data1.jsonl dataManchester.csv\n",
    "\n",
    "How much do people actually tweet?\n",
    "\n",
    "# get all tweets, january Preston 3 hours, about 1,200,000 just for 1 month of vegan tweets from Preston... file size?\n",
    "# Took about 32 hours with some hiccups, downloaded 1,187,582 Tweets (1.2 mill) this file is about 4.2 GB as well.\n",
    "twarc2 search --archive --max-results 100 --start-time \"2019-01-01\" --end-time \"2019-01-30\" \"vegan OR plant-based OR plant based OR veganism -is:retweet --geocode 53.763208,-2.699540,3mi\" dataPreston.jsonl\n",
    "\n",
    "# CSV conversion here took about 10 minutes luckily!\n",
    "twarc2 csv dataPreston.jsonl PrestonJan2019.csv\n",
    "\n",
    "# Processing took about 2 minutes to drop all retweets and replies. 37% of these tweets are original content.\n",
    "# Once tidied for our research question this file is only 135MB, too big to store on Github sadly.\n",
    "\n",
    "# get 250 tweets each three day period, london\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-01\" --end-time \"2021-01-30\" \"(vegan OR plant-based OR plant based OR veganism) point_radius:[51.507351 -0.127758 25mi] -is:retweet\" data1.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-04\" --end-time \"2019-01-6\" \"vegan OR plant-based OR plant based OR veganism --geocode 48.8566, 2.3522,10mi -is:retweet\" data2.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-07\" --end-time \"2019-01-9\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data3.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-10\" --end-time \"2019-01-12\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data4.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-13\" --end-time \"2019-01-15\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data5.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-16\" --end-time \"2019-01-18\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data6.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-19\" --end-time \"2019-01-21\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data7.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-22\" --end-time \"2019-01-24\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data8.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-25\" --end-time \"2019-01-27\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data9.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-28\" --end-time \"2019-01-30\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data10.jsonl\n",
    "\n",
    "# new search structure\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) point_radius:[-0.127758 51.507351 5mi]' londonGeoPointRadius.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) place:london' londonGeoPlace.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) point_radius:[-2.242631 53.480759 5mi]' manchesterGeoPointRadius.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) place:manchester' manchesterGeoPlace.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) point_radius:[-2.703440 53.757729 5mi]' prestonGeoPointRadius.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) place:preston' prestonGeoPlace.jsonl\n",
    "\n",
    "# convert jsonl to csv\n",
    "twarc2 csv londonGeoPointRadius.jsonl londonGeoPointRadius.csv\n",
    "twarc2 csv londonGeoPlace.jsonl londonGeoPlace.csv\n",
    "twarc2 csv manchesterGeoPointRadius.jsonl manchesterGeoPointRadius.csv\n",
    "twarc2 csv manchesterGeoPlace.jsonl manchesterGeoPlace.csv\n",
    "twarc2 csv prestonGeoPointRadius.jsonl prestonGeoPointRadius.csv\n",
    "twarc2 csv prestonGeoPlace.jsonl prestonGeoPlace.csv\n",
    "\n",
    "pip install twarc-csv\n",
    "twarc2 csv data.jsonl data.csv\n",
    "\n",
    "twarc2 csv data1.jsonl data1.csv\n",
    "twarc2 csv data2.jsonl data2.csv\n",
    "twarc2 csv data3.jsonl data3.csv\n",
    "twarc2 csv data4.jsonl data4.csv\n",
    "twarc2 csv data5.jsonl data5.csv\n",
    "twarc2 csv data6.jsonl data6.csv\n",
    "twarc2 csv data7.jsonl data7.csv\n",
    "twarc2 csv data8.jsonl data8.csv\n",
    "twarc2 csv data9.jsonl data9.csv\n",
    "twarc2 csv data10.jsonl data10.csv\n",
    "\n",
    "\n",
    "The API itself delivers those tweets truncated, but you can find the full retweeted text inside the text field of the referenced_tweets object.\n",
    "\n",
    "\n",
    "https://github.com/alblaine/twarc-tutorial\n",
    "https://github.com/jeffcsauer/twarc-v2-tutorials/blob/master/twarc_fas.md\n",
    "https://data.page/json/csv\n",
    "https://github.com/pbinkley/twarc-report\n",
    "\n",
    "Explore get old tweets\n",
    "https://pypi.org/project/GetOldTweets3/\n",
    "https://github.com/Mottl/GetOldTweets3/issues/98\n",
    "https://github.com/twitterdev/search-tweets-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-talk notes for Speaker!\n",
    "* Delete Academic tier app\n",
    "* get backup API keys\n",
    "\n",
    "During talk:\n",
    "* Open a terminal tab, and put in side pane\n",
    "* move to this folder cd .\\Documents\\GitHub\\working-with-twitter-data\\\n",
    "* Open the [Twitter Developer dashboard](https://developer.twitter.com/en/portal/dashboard)\n",
    "* Zoom in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Archive Search\n",
    "In this notebook we detail my recommended route to collecting Twitter Archive data. Through the usual free, or professional API tiers you can only access at most the last 30 days of Twitter data. This is adequate if you want to start collecting and curating a Twitter dataset, but largely useless if you want to look at the history of Twitter.\n",
    "\n",
    "Twitters archive search was released as part of Twitter's V2 API in August 2020, as such it's relatively new and largely unsupported by open source packages.\n",
    "Twitters documentation, and community tutorials have also changed a lot in this time.\n",
    "\n",
    "There are a few packages that can play with this V2 API, but my personal recommendation is [Twarc](https://github.com/DocNow/twarc). There are also a few plugins we can use to convert the output into a CSV file, and various other helpers.\n",
    "\n",
    "This package is a little weird as it runs as a command-line tool. It can be used as a Python package but in this regard the documentation is less clear currently.\n",
    "As this is a command-line tool, it's a little tricky to demo so most code cells here will exist to be copied into the terminal, and details for that installation are outlined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "You will need Python 3 and pip3 availible on your local machine. I recommend doing this by installing [Anaconda](https://docs.anaconda.com/anaconda/install/index.html)\n",
    "\n",
    "We can check these exist by typing the following:\n",
    "```\n",
    "python\n",
    "```\n",
    "which should open a REPL and print out our python version.\n",
    "And:\n",
    "```\n",
    "pip3\n",
    "```\n",
    "which should log out the manual for pip3. If these don't happen you will need to install these [here](https://www.python.org/downloads/) which may take some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Twarc\n",
    "First check if you already have twarc installed:\n",
    "```\n",
    "twarc\n",
    "```\n",
    "You should see twarc is not recognized.\n",
    "\n",
    "Let's install it with:\n",
    "```\n",
    "pip3 install twarc\n",
    "```\n",
    "\n",
    "OR by running the below code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install twarc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twarc time!\n",
    "Now we should have twarc installed, running `twarc` again will log out all the options we have.\n",
    "\n",
    "What we actually need is `twarc2` which supports the new V2 API, which has academic access! If you've got Python 3 you should be able to run this and see you already have twarc2. If you cannot run twarc2 follow the details for your OS [On the Twarc2 installation page](https://twarc-project.readthedocs.io/en/latest/twarc2_en_us/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration & API keys\n",
    "Now comes the annoying bit. To talk to a web-based data source we need API keys so Twitter knows who is asking for millions of their tweets. I suggest not being to concerned with how this part works, we are here to collect our data and get out!\n",
    "\n",
    "## Twitter Developer Portal\n",
    "Before using twarc you will need to create an application and attach it to an project on your [Twitter Developer Portal](https://developer.twitter.com/en/portal/dashboard).\n",
    "\n",
    "1. Create an App\n",
    "2. Note down your API key, API key secret and Bearer token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING - copy the bearer in full\n",
    "bearer = 'AAAAAAAAAAAAAAAAAAAAAI2YUgEAAAAAorejjApTqxel4SAm40SUGVvmmLg%3DqsKBooczuNoIYtjxbToU8oaMiRFj2tNBdv9pVkFwyNcRdHm1w0'\n",
    "api_key = '5HP4wAvN6z4O4GxMrRPuonLlk'\n",
    "api_key_secret = 'j5NjPMcMTe7iLDaQqgObKZKnyz6TqGRA0d4Btb5kSyfbacncXr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run\n",
    "```\n",
    "twarc2 configure\n",
    "```\n",
    "\n",
    "Follow the instructions:\n",
    "1. Enter your bearer token\n",
    "2. say y to optional user mode authentication\n",
    "3. Enter API and API secret\n",
    "4. generate access keys by visiting Twitter\n",
    "5. Enter pin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Twarc\n",
    "As a test to see if this is working run the following:\n",
    "```\n",
    "twarc2 search --archive --limit 100 vegan 10vegan.jsonl\n",
    "```\n",
    "We will build up to this, and more shortly.\n",
    "\n",
    "so let's break that request down:\n",
    "* twarc2 - use twarc with the V2 API\n",
    "* search - use the Twitter search endpoint\n",
    "* --archive - make an archive search\n",
    "* --limit 10 - only give me 10 tweets back\n",
    "* vegan - our search term\n",
    "* tweets.jsonl - our output file\n",
    "\n",
    "# Dashboarding\n",
    "Each application has a dashboard so we can check how close we are to our limit, For academic proejcts we can collect 10,000,000 tweets a month.\n",
    "\n",
    "So two questions come to mind:\n",
    "1. Did we hit the archive?\n",
    "2. Have we actually got ten tweets about veganism\n",
    "\n",
    "To answer either we need to look at the data. JSON isn't very readable so it's time to look at some Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read in the data we need to make use of some python packages\n",
    "import pandas as pd #pandas, our data manipulation library\n",
    "import numpy as np #numpy, to support matrix style tables.\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>source</th>\n",
       "      <th>entities</th>\n",
       "      <th>text</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>attachments</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1448256039304904704</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>1014560119</td>\n",
       "      <td>1448256039304904704</td>\n",
       "      <td>everyone</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>2021-10-13T11:55:21.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>{'urls': [{'start': 277, 'end': 300, 'url': 'h...</td>\n",
       "      <td>#BlackLivesMatter #NickiMinaj #MAGA #2A #Alber...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'media_keys': ['7_1448255956710612995']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1448255911387074560</td>\n",
       "      <td>[{'domain': {'id': '3', 'name': 'TV Shows', 'd...</td>\n",
       "      <td>1145413674296905733</td>\n",
       "      <td>1448255911387074560</td>\n",
       "      <td>everyone</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>2021-10-13T11:54:51.000Z</td>\n",
       "      <td>und</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>{'urls': [{'start': 197, 'end': 220, 'url': 'h...</td>\n",
       "      <td>#BREAKING #Trending #BlackHistoryMonth #BlackL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1448255751835762697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1225963506186489856</td>\n",
       "      <td>1448255751835762697</td>\n",
       "      <td>everyone</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>2021-10-13T11:54:13.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 15, 'usernam...</td>\n",
       "      <td>RT @B1SanDiego1: Remember fellas, if we don't ...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1448252514436993...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1448255454216343555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2826536509</td>\n",
       "      <td>1448255454216343555</td>\n",
       "      <td>everyone</td>\n",
       "      <td>{'retweet_count': 12, 'reply_count': 0, 'like_...</td>\n",
       "      <td>2021-10-13T11:53:02.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 15, 'usernam...</td>\n",
       "      <td>RT @INQUEST_ORG: 游닉UNITED FAMILIES &amp;amp; FRIEND...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1448202976561147...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1448255441901867010</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>34196593</td>\n",
       "      <td>1448255441901867010</td>\n",
       "      <td>everyone</td>\n",
       "      <td>{'retweet_count': 34, 'reply_count': 0, 'like_...</td>\n",
       "      <td>2021-10-13T11:52:59.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 15, 'usernam...</td>\n",
       "      <td>RT @MsArielKnox: This video gives me goosebump...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1448123940996534...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conversation_id                                context_annotations  \\\n",
       "95  1448256039304904704  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "96  1448255911387074560  [{'domain': {'id': '3', 'name': 'TV Shows', 'd...   \n",
       "97  1448255751835762697                                                NaN   \n",
       "98  1448255454216343555                                                NaN   \n",
       "99  1448255441901867010  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "\n",
       "              author_id                   id reply_settings  \\\n",
       "95           1014560119  1448256039304904704       everyone   \n",
       "96  1145413674296905733  1448255911387074560       everyone   \n",
       "97  1225963506186489856  1448255751835762697       everyone   \n",
       "98           2826536509  1448255454216343555       everyone   \n",
       "99             34196593  1448255441901867010       everyone   \n",
       "\n",
       "                                       public_metrics  \\\n",
       "95  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "96  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "97  {'retweet_count': 1, 'reply_count': 0, 'like_c...   \n",
       "98  {'retweet_count': 12, 'reply_count': 0, 'like_...   \n",
       "99  {'retweet_count': 34, 'reply_count': 0, 'like_...   \n",
       "\n",
       "                  created_at lang  possibly_sensitive               source  \\\n",
       "95  2021-10-13T11:55:21.000Z   en               False  Twitter for Android   \n",
       "96  2021-10-13T11:54:51.000Z  und               False   Twitter for iPhone   \n",
       "97  2021-10-13T11:54:13.000Z   en               False  Twitter for Android   \n",
       "98  2021-10-13T11:53:02.000Z   en               False   Twitter for iPhone   \n",
       "99  2021-10-13T11:52:59.000Z   en               False  Twitter for Android   \n",
       "\n",
       "                                             entities  \\\n",
       "95  {'urls': [{'start': 277, 'end': 300, 'url': 'h...   \n",
       "96  {'urls': [{'start': 197, 'end': 220, 'url': 'h...   \n",
       "97  {'mentions': [{'start': 3, 'end': 15, 'usernam...   \n",
       "98  {'mentions': [{'start': 3, 'end': 15, 'usernam...   \n",
       "99  {'mentions': [{'start': 3, 'end': 15, 'usernam...   \n",
       "\n",
       "                                                 text  \\\n",
       "95  #BlackLivesMatter #NickiMinaj #MAGA #2A #Alber...   \n",
       "96  #BREAKING #Trending #BlackHistoryMonth #BlackL...   \n",
       "97  RT @B1SanDiego1: Remember fellas, if we don't ...   \n",
       "98  RT @INQUEST_ORG: 游닉UNITED FAMILIES &amp; FRIEND...   \n",
       "99  RT @MsArielKnox: This video gives me goosebump...   \n",
       "\n",
       "                                    referenced_tweets  \\\n",
       "95                                                NaN   \n",
       "96                                                NaN   \n",
       "97  [{'type': 'retweeted', 'id': '1448252514436993...   \n",
       "98  [{'type': 'retweeted', 'id': '1448202976561147...   \n",
       "99  [{'type': 'retweeted', 'id': '1448123940996534...   \n",
       "\n",
       "                                  attachments in_reply_to_user_id  \n",
       "95  {'media_keys': ['7_1448255956710612995']}                 NaN  \n",
       "96                                        NaN                 NaN  \n",
       "97                                        NaN                 NaN  \n",
       "98                                        NaN                 NaN  \n",
       "99                                        NaN                 NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next we read our JSON into a dataframe.\n",
    "data = json.load(open('data/10vegan.jsonl'))\n",
    "df = pd.DataFrame(data[\"data\"])\n",
    "\n",
    "# check the last five rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter URL formats\n",
    "A good next step is to actually inspect some of these tweets and see what data we get.\n",
    "\n",
    "If we navigate to any individual tweet on Twitter, for example `https://twitter.com/JosephAllen1234/status/1448222861701832704`\n",
    "\n",
    "This number at the end is our tweet ID. if we paste any ID from our dataset there we can navigate to it.\n",
    "\n",
    "You'll also notice some nested JSON files, we haven't really flattened out this data fully.\n",
    "\n",
    "## Twarc convert to CSV\n",
    "We aren't the first people to want to flatten this JSON object, there is a twarc plugin to convert to CSV.\n",
    "\n",
    "First make sure twarc is up to date with:\n",
    "```\n",
    "pip3 install --upgrade twarc\n",
    "twarc2 configure\n",
    "```\n",
    "\n",
    "Then install the twarc-csv plugin:\n",
    "```\n",
    "pip3 install --upgrade twarc-csv\n",
    "```\n",
    "OR if running straight from anaconda run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\joe\\appdata\\local\\pip\\cache\\wheels\\be\\ea\\a1\\fab25a5e515163486c5a57f3a0631330928511fe07c63f60b2\\twarc_csv-0.3.8-py3-none-any.whl\n",
      "Collecting more-itertools>=8.7.0\n",
      "  Using cached more_itertools-8.10.0-py3-none-any.whl (51 kB)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=1.2.5 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from twarc-csv) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: twarc>=2.4.0 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from twarc-csv) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.59.0 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from twarc-csv) (4.62.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from pandas>=1.2.5->twarc-csv) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from pandas>=1.2.5->twarc-csv) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from pandas>=1.2.5->twarc-csv) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: click-plugins>=1 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from twarc>=2.4.0->twarc-csv) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: click<9,>=7 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from twarc>=2.4.0->twarc-csv) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=1.3 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from twarc>=2.4.0->twarc-csv) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: click-config-file>=0.6 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from twarc>=2.4.0->twarc-csv) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: humanize>=3.9 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from twarc>=2.4.0->twarc-csv) (3.12.0)\n",
      "Requirement already satisfied, skipping upgrade: colorama; platform_system == \"Windows\" in c:\\users\\joe\\anaconda3\\lib\\site-packages (from tqdm>=4.59.0->twarc-csv) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.5->twarc-csv) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from requests-oauthlib>=1.3->twarc>=2.4.0->twarc-csv) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from requests-oauthlib>=1.3->twarc>=2.4.0->twarc-csv) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: configobj>=5.0.6 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from click-config-file>=0.6->twarc>=2.4.0->twarc-csv) (5.0.6)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\joe\\anaconda3\\lib\\site-packages (from humanize>=3.9->twarc>=2.4.0->twarc-csv) (50.3.1.post20201107)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.4.0->twarc-csv) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.4.0->twarc-csv) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.4.0->twarc-csv) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.4.0->twarc-csv) (2.10)\n",
      "Installing collected packages: more-itertools, twarc-csv\n",
      "  Attempting uninstall: more-itertools\n",
      "    Found existing installation: more-itertools 8.6.0\n",
      "    Uninstalling more-itertools-8.6.0:\n",
      "      Successfully uninstalled more-itertools-8.6.0\n",
      "Successfully installed more-itertools-8.10.0 twarc-csv-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade twarc-csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can convert with the following pattern:\n",
    "```\n",
    "twarc2 csv tweets.jsonl tweets.csv\n",
    "```\n",
    "renaming files where needed.\n",
    "\n",
    "So lets convert our 10 tweets.\n",
    "```\n",
    "twarc2 csv 10vegan.jsonl 10vegan.csv\n",
    "```\n",
    "\n",
    "Now we should be able to read this in directly with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>attachments.media</th>\n",
       "      <th>attachments.media_keys</th>\n",
       "      <th>attachments.poll.duration_minutes</th>\n",
       "      <th>attachments.poll.end_datetime</th>\n",
       "      <th>attachments.poll.id</th>\n",
       "      <th>attachments.poll.options</th>\n",
       "      <th>attachments.poll.voting_status</th>\n",
       "      <th>...</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>source</th>\n",
       "      <th>withheld.scope</th>\n",
       "      <th>withheld.copyright</th>\n",
       "      <th>withheld.country_codes</th>\n",
       "      <th>type</th>\n",
       "      <th>__twarc.retrieved_at</th>\n",
       "      <th>__twarc.url</th>\n",
       "      <th>__twarc.version</th>\n",
       "      <th>Unnamed: 93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1448252514436993026</td>\n",
       "      <td>2021-10-13T11:41:21.000Z</td>\n",
       "      <td>Remember fellas, if we don't specifically date...</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>[\"3_1448252503775088647\", \"3_14482525121887805...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>2021-10-13T12:18:22+00:00</td>\n",
       "      <td>https://api.twitter.com/2/tweets/search/all?ex...</td>\n",
       "      <td>2.7.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1448255751835762697</td>\n",
       "      <td>2021-10-13T11:54:13.000Z</td>\n",
       "      <td>RT @B1SanDiego1: Remember fellas, if we don't ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-10-13T12:18:22+00:00</td>\n",
       "      <td>https://api.twitter.com/2/tweets/search/all?ex...</td>\n",
       "      <td>2.7.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1448255454216343555</td>\n",
       "      <td>2021-10-13T11:53:02.000Z</td>\n",
       "      <td>RT @INQUEST_ORG: 游닉UNITED FAMILIES &amp;amp; FRIEND...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-10-13T12:18:22+00:00</td>\n",
       "      <td>https://api.twitter.com/2/tweets/search/all?ex...</td>\n",
       "      <td>2.7.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1448123940996534281</td>\n",
       "      <td>2021-10-13T03:10:27.000Z</td>\n",
       "      <td>This video gives me goosebumps no matter how m...</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>[\"7_1308850434765852672\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>2021-10-13T12:18:22+00:00</td>\n",
       "      <td>https://api.twitter.com/2/tweets/search/all?ex...</td>\n",
       "      <td>2.7.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1448255441901867010</td>\n",
       "      <td>2021-10-13T11:52:59.000Z</td>\n",
       "      <td>RT @MsArielKnox: This video gives me goosebump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-10-13T12:18:22+00:00</td>\n",
       "      <td>https://api.twitter.com/2/tweets/search/all?ex...</td>\n",
       "      <td>2.7.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows 칑 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                created_at  \\\n",
       "129  1448252514436993026  2021-10-13T11:41:21.000Z   \n",
       "130  1448255751835762697  2021-10-13T11:54:13.000Z   \n",
       "131  1448255454216343555  2021-10-13T11:53:02.000Z   \n",
       "132  1448123940996534281  2021-10-13T03:10:27.000Z   \n",
       "133  1448255441901867010  2021-10-13T11:52:59.000Z   \n",
       "\n",
       "                                                  text attachments.media  \\\n",
       "129  Remember fellas, if we don't specifically date...          [{}, {}]   \n",
       "130  RT @B1SanDiego1: Remember fellas, if we don't ...               NaN   \n",
       "131  RT @INQUEST_ORG: 游닉UNITED FAMILIES &amp; FRIEND...               NaN   \n",
       "132  This video gives me goosebumps no matter how m...              [{}]   \n",
       "133  RT @MsArielKnox: This video gives me goosebump...               NaN   \n",
       "\n",
       "                                attachments.media_keys  \\\n",
       "129  [\"3_1448252503775088647\", \"3_14482525121887805...   \n",
       "130                                                NaN   \n",
       "131                                                NaN   \n",
       "132                          [\"7_1308850434765852672\"]   \n",
       "133                                                NaN   \n",
       "\n",
       "     attachments.poll.duration_minutes  attachments.poll.end_datetime  \\\n",
       "129                                NaN                            NaN   \n",
       "130                                NaN                            NaN   \n",
       "131                                NaN                            NaN   \n",
       "132                                NaN                            NaN   \n",
       "133                                NaN                            NaN   \n",
       "\n",
       "     attachments.poll.id  attachments.poll.options  \\\n",
       "129                  NaN                       NaN   \n",
       "130                  NaN                       NaN   \n",
       "131                  NaN                       NaN   \n",
       "132                  NaN                       NaN   \n",
       "133                  NaN                       NaN   \n",
       "\n",
       "     attachments.poll.voting_status  ...  reply_settings               source  \\\n",
       "129                             NaN  ...        everyone  Twitter for Android   \n",
       "130                             NaN  ...        everyone  Twitter for Android   \n",
       "131                             NaN  ...        everyone   Twitter for iPhone   \n",
       "132                             NaN  ...        everyone      Twitter Web App   \n",
       "133                             NaN  ...        everyone  Twitter for Android   \n",
       "\n",
       "    withheld.scope withheld.copyright withheld.country_codes       type  \\\n",
       "129            NaN                NaN                    NaN  retweeted   \n",
       "130            NaN                NaN                    NaN        NaN   \n",
       "131            NaN                NaN                    NaN        NaN   \n",
       "132            NaN                NaN                    NaN  retweeted   \n",
       "133            NaN                NaN                    NaN        NaN   \n",
       "\n",
       "          __twarc.retrieved_at  \\\n",
       "129  2021-10-13T12:18:22+00:00   \n",
       "130  2021-10-13T12:18:22+00:00   \n",
       "131  2021-10-13T12:18:22+00:00   \n",
       "132  2021-10-13T12:18:22+00:00   \n",
       "133  2021-10-13T12:18:22+00:00   \n",
       "\n",
       "                                           __twarc.url __twarc.version  \\\n",
       "129  https://api.twitter.com/2/tweets/search/all?ex...           2.7.3   \n",
       "130  https://api.twitter.com/2/tweets/search/all?ex...           2.7.3   \n",
       "131  https://api.twitter.com/2/tweets/search/all?ex...           2.7.3   \n",
       "132  https://api.twitter.com/2/tweets/search/all?ex...           2.7.3   \n",
       "133  https://api.twitter.com/2/tweets/search/all?ex...           2.7.3   \n",
       "\n",
       "    Unnamed: 93  \n",
       "129         NaN  \n",
       "130         NaN  \n",
       "131         NaN  \n",
       "132         NaN  \n",
       "133         NaN  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/10vegan.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134 entries, 0 to 133\n",
      "Data columns (total 94 columns):\n",
      " #   Column                                           Non-Null Count  Dtype  \n",
      "---  ------                                           --------------  -----  \n",
      " 0   id                                               134 non-null    int64  \n",
      " 1   created_at                                       134 non-null    object \n",
      " 2   text                                             134 non-null    object \n",
      " 3   attachments.media                                37 non-null     object \n",
      " 4   attachments.media_keys                           37 non-null     object \n",
      " 5   attachments.poll.duration_minutes                0 non-null      float64\n",
      " 6   attachments.poll.end_datetime                    0 non-null      float64\n",
      " 7   attachments.poll.id                              0 non-null      float64\n",
      " 8   attachments.poll.options                         0 non-null      float64\n",
      " 9   attachments.poll.voting_status                   0 non-null      float64\n",
      " 10  attachments.poll_ids                             0 non-null      float64\n",
      " 11  author.id                                        134 non-null    int64  \n",
      " 12  author.created_at                                134 non-null    object \n",
      " 13  author.username                                  134 non-null    object \n",
      " 14  author.name                                      134 non-null    object \n",
      " 15  author.description                               117 non-null    object \n",
      " 16  author.entities.description.cashtags             0 non-null      float64\n",
      " 17  author.entities.description.hashtags             42 non-null     object \n",
      " 18  author.entities.description.mentions             21 non-null     object \n",
      " 19  author.entities.description.urls                 10 non-null     object \n",
      " 20  author.entities.url.urls                         66 non-null     object \n",
      " 21  author.location                                  82 non-null     object \n",
      " 22  author.pinned_tweet_id                           71 non-null     float64\n",
      " 23  author.profile_image_url                         134 non-null    object \n",
      " 24  author.protected                                 134 non-null    bool   \n",
      " 25  author.public_metrics.followers_count            134 non-null    int64  \n",
      " 26  author.public_metrics.following_count            134 non-null    int64  \n",
      " 27  author.public_metrics.listed_count               134 non-null    int64  \n",
      " 28  author.public_metrics.tweet_count                134 non-null    int64  \n",
      " 29  author.url                                       66 non-null     object \n",
      " 30  author.verified                                  134 non-null    bool   \n",
      " 31  author.withheld.scope                            0 non-null      float64\n",
      " 32  author.withheld.copyright                        0 non-null      float64\n",
      " 33  author.withheld.country_codes                    0 non-null      float64\n",
      " 34  author_id                                        134 non-null    int64  \n",
      " 35  context_annotations                              68 non-null     object \n",
      " 36  conversation_id                                  134 non-null    int64  \n",
      " 37  entities.annotations                             24 non-null     object \n",
      " 38  entities.cashtags                                0 non-null      float64\n",
      " 39  entities.hashtags                                107 non-null    object \n",
      " 40  entities.mentions                                92 non-null     object \n",
      " 41  entities.urls                                    70 non-null     object \n",
      " 42  geo.coordinates.coordinates                      0 non-null      float64\n",
      " 43  geo.coordinates.type                             0 non-null      float64\n",
      " 44  geo.country                                      0 non-null      float64\n",
      " 45  geo.country_code                                 0 non-null      float64\n",
      " 46  geo.full_name                                    0 non-null      float64\n",
      " 47  geo.geo.bbox                                     0 non-null      float64\n",
      " 48  geo.geo.type                                     0 non-null      float64\n",
      " 49  geo.id                                           0 non-null      float64\n",
      " 50  geo.name                                         0 non-null      float64\n",
      " 51  geo.place_id                                     3 non-null      object \n",
      " 52  geo.place_type                                   0 non-null      float64\n",
      " 53  in_reply_to_user.id                              10 non-null     float64\n",
      " 54  in_reply_to_user.created_at                      10 non-null     object \n",
      " 55  in_reply_to_user.username                        10 non-null     object \n",
      " 56  in_reply_to_user.name                            10 non-null     object \n",
      " 57  in_reply_to_user.description                     9 non-null      object \n",
      " 58  in_reply_to_user.entities.description.cashtags   0 non-null      float64\n",
      " 59  in_reply_to_user.entities.description.hashtags   3 non-null      object \n",
      " 60  in_reply_to_user.entities.description.mentions   4 non-null      object \n",
      " 61  in_reply_to_user.entities.description.urls       1 non-null      object \n",
      " 62  in_reply_to_user.entities.url.urls               3 non-null      object \n",
      " 63  in_reply_to_user.location                        8 non-null      object \n",
      " 64  in_reply_to_user.pinned_tweet_id                 7 non-null      float64\n",
      " 65  in_reply_to_user.profile_image_url               10 non-null     object \n",
      " 66  in_reply_to_user.protected                       10 non-null     object \n",
      " 67  in_reply_to_user.public_metrics.followers_count  10 non-null     float64\n",
      " 68  in_reply_to_user.public_metrics.following_count  10 non-null     float64\n",
      " 69  in_reply_to_user.public_metrics.listed_count     10 non-null     float64\n",
      " 70  in_reply_to_user.public_metrics.tweet_count      10 non-null     float64\n",
      " 71  in_reply_to_user.url                             3 non-null      object \n",
      " 72  in_reply_to_user.verified                        10 non-null     object \n",
      " 73  in_reply_to_user.withheld.scope                  0 non-null      float64\n",
      " 74  in_reply_to_user.withheld.copyright              0 non-null      float64\n",
      " 75  in_reply_to_user.withheld.country_codes          0 non-null      float64\n",
      " 76  in_reply_to_user_id                              10 non-null     float64\n",
      " 77  lang                                             134 non-null    object \n",
      " 78  possibly_sensitive                               134 non-null    bool   \n",
      " 79  public_metrics.like_count                        134 non-null    int64  \n",
      " 80  public_metrics.quote_count                       134 non-null    int64  \n",
      " 81  public_metrics.reply_count                       134 non-null    int64  \n",
      " 82  public_metrics.retweet_count                     134 non-null    int64  \n",
      " 83  referenced_tweets                                74 non-null     object \n",
      " 84  reply_settings                                   134 non-null    object \n",
      " 85  source                                           134 non-null    object \n",
      " 86  withheld.scope                                   0 non-null      float64\n",
      " 87  withheld.copyright                               0 non-null      float64\n",
      " 88  withheld.country_codes                           0 non-null      float64\n",
      " 89  type                                             42 non-null     object \n",
      " 90  __twarc.retrieved_at                             134 non-null    object \n",
      " 91  __twarc.url                                      134 non-null    object \n",
      " 92  __twarc.version                                  134 non-null    object \n",
      " 93  Unnamed: 93                                      0 non-null      float64\n",
      "dtypes: bool(3), float64(37), int64(12), object(42)\n",
      "memory usage: 95.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# List out all columns we have access to.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - London Veganuary 2019\n",
    "It's not enough that we simply search all tweets, in fact we will very quickly hit our 10,000,000 tweet limit with this approach, adding a one month delay to our research.\n",
    "\n",
    "## How useful is 10,000,000 tweets?\n",
    "From my previous attempts at this collecting all tweets containing the word vegan in January 2019 returned 1.2 million tweets. This took 32 hours and resulted in a 4.2GB file.\n",
    "\n",
    "There are an estimated 500 million tweets uploaded every day.\n",
    "As such it's important to narrow the scope of your project, and focus on very specific time periods.\n",
    "\n",
    "## The query\n",
    "We are asking \"How did the vegan perception change over Veganuary 2019\" This was the first largely adopted veganuary, famously the announcment of Greggs sausage rolls. We need to get only tweets from this period, near London, and we are not interested in collecting any Retweets or replies.\n",
    "\n",
    "we need the following data:\n",
    "* tweet ID\n",
    "* tweet text\n",
    "* user names and IDs\n",
    "* Anything that will help us check locations\n",
    "* the number of retweets and favorites on each tweet\n",
    "\n",
    "Let's build this up piece by piece\n",
    "\n",
    "### Custom search term\n",
    "We simply write the term we are searching for, \"vegan\", after the search keyword.\n",
    "WARNING - DO NOT RUN THESE WITHOUT --limit\n",
    "```\n",
    "twarc2 search vegan vegan.jsonl\n",
    "```\n",
    "\n",
    "what about vegatarians? What about plant-based diets? For multiple terms we wrap the search in quotes. We can also OR, AND and use other operators to specify what we want.\n",
    "\n",
    "```\n",
    "twarc2 search \"vegan OR vegetarian OR plant-based\" vegan.jsonl\n",
    "```\n",
    "\n",
    "### Limit the search\n",
    "Unless you want to capture all tweets that match this search, you should limit your search. adding `--limit x` replacing x with the number of tweets you want will help you here. \n",
    "\n",
    "```\n",
    "twarc2 search --limit 100 \"vegan OR vegetarian OR plant-based\" vegan.jsonl\n",
    "```\n",
    "\n",
    "### Archive search\n",
    "The `--archive` flag lets Twitter know we want to access more than the last 7 days. You will only be allowed to do this with the academic tier, it won't fail otherwise it will just give you recent tweets instead.\n",
    "\n",
    "```\n",
    "twarc2 search --archive --limit 100 \"vegan OR vegetarian OR plant-based\" vegan.jsonl\n",
    "```\n",
    "\n",
    "### Start and End times\n",
    "Adding a `--start-time` and `--end-time` flag lets you set start and end times to your archive search. These require dates in the format YYYY-MM-DD.\n",
    "\n",
    "```\n",
    "twarc2 search --archive --limit 100 --start-time \"2019-01-04\" --end-time \"2019-01-06\" \"vegan OR vegetarian OR plant-based\" vegan.jsonl\n",
    "```\n",
    "\n",
    "### Location search\n",
    "finally we can add reducing by location. This is one of Twitters built-in operators and so it must go in the search term, rather than be a flag for twarc. We add `point_radius:[lon,lat,radius]`, see the below example. You can use a tool like [this](https://www.latlong.net/) to find the lon/lat needed.\n",
    "\n",
    "```\n",
    "twarc2 search --archive --limit 100 --start-time \"2019-01-04\" --end-time \"2019-01-06\" \"vegan OR vegetarian OR plant-based point_radius:[-0.127758 51.507351 5mi]\" vegan.jsonl\n",
    "```\n",
    "\n",
    "Or a Place search\n",
    "```\n",
    "twarc2 search --archive --limit 100 --start-time \"2019-01-04\" --end-time \"2019-01-06\" \"vegan OR vegetarian OR plant-based place:london\" vegan.jsonl\n",
    "```\n",
    "\n",
    "So that's everything we need. There are some additional rules you can use based on your API tier [here](https://developer.twitter.com/en/docs/twitter-api/premium/rules-and-filtering/operators-by-product)\n",
    "\n",
    "Let's run this one last time to collect our data.\n",
    "```\n",
    "twarc2 search --archive --limit 100 --start-time \"2019-01-04\" --end-time \"2019-01-06\" \"vegan OR vegetarian OR plant-based point_radius:[-0.127758 51.507351 5mi]\" 100VeganLondonJan2019.jsonl\n",
    "```\n",
    "Then convert it to a csv\n",
    "```\n",
    "twarc2 csv 100VeganLondonJan2019.jsonl 100VeganLondonJan2019.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "## Is 10,000,000 tweets a lot?\n",
    "## CSV conversion\n",
    "## de duped data\n",
    "## ignore retweets\n",
    "## ignore images etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
