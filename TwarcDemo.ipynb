{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "* test Twarc can be used in anaconda command line\n",
    "* Write intro to this scenario\n",
    "\n",
    "Introduction to scenario\n",
    "\n",
    "print(tweet.id)\n",
    "print(tweet.created_at)\n",
    "print(tweet.text)\n",
    "print(tweet.user.id)\n",
    "print(tweet.user.name)\n",
    "print(tweet.user.screen_name)\n",
    "print(tweet.user.location)\n",
    "print(tweet.user.followers_count)\n",
    "print(tweet.user.created_at)\n",
    "print(tweet.user.geo_enabled)\n",
    "print(tweet.geo)\n",
    "print(tweet.coordinates)\n",
    "print(tweet.place)\n",
    "print(tweet.retweet_count)\n",
    "print(tweet.favorite_count)\n",
    "\n",
    "restrict by location\n",
    "no replies\n",
    "no retweets\n",
    "start and end date\n",
    "tweet needs extended mode\n",
    "Only get tweets with locations\n",
    "\n",
    "\n",
    "https://developer.twitter.com/en/docs/twitter-api/premium/rules-and-filtering/operators-by-product\n",
    "\n",
    "we can use place, place_country and some similar. There doesn't seem to be any way of filtering retweets or replies without being on a paid tier.\n",
    "This can be a city, or a country. We can also restrict the language down to restrict english inputs if we need that.\n",
    "We can set a start and end date.\n",
    "Full_text is stored differently for retweets and tweets so we could take all, or choose only original content. we would hit the same API limit though.\n",
    "\n",
    "Limit seems to be at 300 per 15 minutes.\n",
    "We can run this every 15 minutes with different locations, and different time periods. I would ask here does time periods give us much?\n",
    "\n",
    "Twarc\n",
    "\n",
    "twarc2 configure\n",
    "YYYY-MM-DD\n",
    "-is_retweet -RT\n",
    "https://twittercommunity.com/t/exclude-retweets-in-api-v2/156357/5\n",
    "\n",
    "# get all tweets, january London\n",
    "twarc2 search --archive --max-results 100 --start-time \"2019-01-01\" --end-time \"2019-01-30\" \"(vegan OR plant-based OR plant based OR veganism) -is:retweet --geocode 51.507351,-0.127758,10mi\" data1.jsonl\n",
    "twarc2 csv data1.jsonl dataManchester.csv\n",
    "\n",
    "How much do people actually tweet?\n",
    "\n",
    "# get all tweets, january Preston 3 hours, about 1,200,000 just for 1 month of vegan tweets from Preston... file size?\n",
    "# Took about 32 hours with some hiccups, downloaded 1,187,582 Tweets (1.2 mill) this file is about 4.2 GB as well.\n",
    "twarc2 search --archive --max-results 100 --start-time \"2019-01-01\" --end-time \"2019-01-30\" \"vegan OR plant-based OR plant based OR veganism -is:retweet --geocode 53.763208,-2.699540,3mi\" dataPreston.jsonl\n",
    "\n",
    "# CSV conversion here took about 10 minutes luckily!\n",
    "twarc2 csv dataPreston.jsonl PrestonJan2019.csv\n",
    "\n",
    "# Processing took about 2 minutes to drop all retweets and replies. 37% of these tweets are original content.\n",
    "# Once tidied for our research question this file is only 135MB, too big to store on Github sadly.\n",
    "\n",
    "# get 250 tweets each three day period, london\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-01\" --end-time \"2021-01-30\" \"(vegan OR plant-based OR plant based OR veganism) point_radius:[51.507351 -0.127758 25mi] -is:retweet\" data1.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-04\" --end-time \"2019-01-6\" \"vegan OR plant-based OR plant based OR veganism --geocode 48.8566, 2.3522,10mi -is:retweet\" data2.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-07\" --end-time \"2019-01-9\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data3.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-10\" --end-time \"2019-01-12\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data4.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-13\" --end-time \"2019-01-15\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data5.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-16\" --end-time \"2019-01-18\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data6.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-19\" --end-time \"2019-01-21\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data7.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-22\" --end-time \"2019-01-24\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data8.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-25\" --end-time \"2019-01-27\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data9.jsonl\n",
    "twarc2 search --archive --limit 250 --max-results 100 --start-time \"2019-01-28\" --end-time \"2019-01-30\" \"vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet\" data10.jsonl\n",
    "\n",
    "# new search structure\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) point_radius:[-0.127758 51.507351 5mi]' londonGeoPointRadius.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) place:london' londonGeoPlace.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) point_radius:[-2.242631 53.480759 5mi]' manchesterGeoPointRadius.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) place:manchester' manchesterGeoPlace.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) point_radius:[-2.703440 53.757729 5mi]' prestonGeoPointRadius.jsonl\n",
    "twarc2 search --archive --start-time \"2019-01-01\" --end-time \"2019-01-30\" '(vegan OR plant-based OR \"plant based\" OR veganism) place:preston' prestonGeoPlace.jsonl\n",
    "\n",
    "# convert jsonl to csv\n",
    "twarc2 csv londonGeoPointRadius.jsonl londonGeoPointRadius.csv\n",
    "twarc2 csv londonGeoPlace.jsonl londonGeoPlace.csv\n",
    "twarc2 csv manchesterGeoPointRadius.jsonl manchesterGeoPointRadius.csv\n",
    "twarc2 csv manchesterGeoPlace.jsonl manchesterGeoPlace.csv\n",
    "twarc2 csv prestonGeoPointRadius.jsonl prestonGeoPointRadius.csv\n",
    "twarc2 csv prestonGeoPlace.jsonl prestonGeoPlace.csv\n",
    "\n",
    "pip install twarc-csv\n",
    "twarc2 csv data.jsonl data.csv\n",
    "\n",
    "twarc2 csv data1.jsonl data1.csv\n",
    "twarc2 csv data2.jsonl data2.csv\n",
    "twarc2 csv data3.jsonl data3.csv\n",
    "twarc2 csv data4.jsonl data4.csv\n",
    "twarc2 csv data5.jsonl data5.csv\n",
    "twarc2 csv data6.jsonl data6.csv\n",
    "twarc2 csv data7.jsonl data7.csv\n",
    "twarc2 csv data8.jsonl data8.csv\n",
    "twarc2 csv data9.jsonl data9.csv\n",
    "twarc2 csv data10.jsonl data10.csv\n",
    "\n",
    "\n",
    "The API itself delivers those tweets truncated, but you can find the full retweeted text inside the text field of the referenced_tweets object.\n",
    "\n",
    "\n",
    "https://github.com/alblaine/twarc-tutorial\n",
    "https://github.com/jeffcsauer/twarc-v2-tutorials/blob/master/twarc_fas.md\n",
    "https://data.page/json/csv\n",
    "https://github.com/pbinkley/twarc-report\n",
    "\n",
    "Explore get old tweets\n",
    "https://pypi.org/project/GetOldTweets3/\n",
    "https://github.com/Mottl/GetOldTweets3/issues/98\n",
    "https://github.com/twitterdev/search-tweets-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
